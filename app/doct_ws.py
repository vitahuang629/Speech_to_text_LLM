import json
import azure.cognitiveservices.speech as speechsdk
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Request, APIRouter
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse
import asyncio
import requests
import os
import time
from datetime import datetime
from collections import defaultdict
from asyncio import Lock
import re
from fastapi.middleware.cors import CORSMiddleware
from datetime import datetime, timedelta, timezone
from fastapi.responses import JSONResponse
from openai import OpenAI
from starlette import websockets

OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
speech_key = os.environ.get("SPEECH_KEY")
speech_region = os.environ.get("SPEECH_REGION")
endpoint_id = os.environ.get("ENDPOINT_ID")


router = APIRouter()

DOCT_MAX_CONNECTIONS = 10
doct_active_connections = set()

# ç”¨æ–¼å„²å­˜æœ€çµ‚è¾¨è­˜çµæœçš„å…¨å±€è®Šæ•¸
doct_final_results = defaultdict(str) #é¿å…æ‰“æ¶
doct_summary_results = defaultdict(str)
doct_result_lock = Lock()
doct_active_sessions = {} #å„²å­˜ session_id: websocket 7/3
doct_last_access_time = {} #key: session_id, value:datetime

clean_interval = 480 #ç§’
data_ttl = 1200 #å­˜æ´»æ™‚é–“(20åˆ†é˜)

class OpenAILLM:
    def __init__(self, model, api_key, temperature=0.7, messages=None):
        self.model = model
        self.temperature = temperature
        self.messages = messages or []
        self.client = OpenAI(api_key=api_key)

    def get_summary(self, text, system_prompt):
        messages = self.messages.copy()
        messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": "user", "content": text})

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=self.temperature
            )
            return response.choices[0].message.content
        except Exception as e:
            print(f"OpenAI APIè«‹æ±‚éŒ¯èª¤: {e}")
            return f"ç²å–æ‘˜è¦æ™‚å‡ºéŒ¯: {str(e)}"


# åˆå§‹åŒ–LLM
llm = OpenAILLM(
    # model="gpt-3.5-turbo",
    model="gpt-4o-mini",
    # api_key=os.getenv("OPENAI_API_KEY"),
    api_key = OPENAI_API_KEY,
    temperature=0.7,
    messages=[{"role": "system", "content": "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„é†«ç¾è«®è©¢ç´€éŒ„åˆ†æå“¡"}]
)

summarize_prompt = (
    """
ä½ æ˜¯å°è©±æ½¤é£¾åŠ©æ‰‹ã€‚

ä»»å‹™ï¼š
1. å°‡é€å­—ç¨¿ä¸­å› èªéŸ³è¾¨è­˜éŒ¯èª¤æˆ–å£èªåŒ–ã€å£åƒã€é‡è¤‡ã€æ–·è£‚é€ æˆçš„éé€šé †èªå¥é€²è¡Œèªå¥ä¿®æ­£èˆ‡èªæ„æ•´ç†ï¼Œä½¿å°è©±å…§å®¹æ¸…æ™°ã€è‡ªç„¶ã€æµæš¢ã€‚
2. ä¿ç•™é€å¥å°è©±çµæ§‹èˆ‡åŸå§‹é †åºã€‚
3. ä¸åˆªæ‰ä»»ä½•å°è©±å…§å®¹ï¼Œåªä¿®æ­£èªå¥é€šé †ã€‚
4. ä¿®æ­£å¾Œçš„èªå¥è¦è‡ªç„¶ã€å®Œæ•´ï¼Œå¯è®€æ€§é«˜ï¼Œä½†ä¸è¦åŠ å…¥æ‘˜è¦ã€è©•è«–æˆ–é¡å¤–è¨Šæ¯ã€‚
5. ä¿ç•™å£èªåŒ–ç‰¹è‰²ï¼Œä½†é¿å…ä¸å¿…è¦çš„é‡è¤‡ã€æ–·å¥ä¸å®Œæ•´ã€éŒ¯èª¤ç”¨è©ã€‚
6. é©ç•¶å°‡ä¸å®Œæ•´æˆ–èªæ„æ¨¡ç³Šçš„å¥å­è£œæˆå®Œæ•´å¥ã€‚

è¼¸å‡ºæ ¼å¼ï¼š
---
ã€æ½¤é£¾éçš„é€å­—ç¨¿ã€‘:
 xxx
---
âš ï¸ åƒ…è¼¸å‡ºæ½¤é£¾å¾Œçš„é€å­—ç¨¿ï¼Œä¸è¦åŠ ä»»ä½•åˆ†ææˆ–åˆ†é¡ã€‚
    """
)

doctor_system_prompt = ("""
ä½ æ˜¯å°ˆæ¥­çš„é†«ç™‚å°è©±åˆ†æåŠ©æ‰‹ï¼Œè² è²¬æ•´ç†ã€Œé†«å¸«èˆ‡å®¢äººä¹‹é–“çš„é€å­—ç¨¿ã€ã€‚
è«‹å‹™å¿…ä¾ç…§é€å­—ç¨¿å…§å®¹é€²è¡Œåˆ†æï¼Œä¸å¾—æé€ ã€æ¨æ¸¬ã€æ“´å¯« ä»»ä½•æœªæåŠè³‡è¨Šã€‚

è«‹é–±è®€é€å­—ç¨¿å¾Œï¼Œä¾ä»¥ä¸‹å®šç¾©è¼¸å‡ºã€Œçµæ§‹åŒ–æ‘˜è¦ã€ï¼š

ã€åˆ†é¡å®šç¾©ã€‘
---
å®¢äººä¸»è¨´ï¼š
æŒ‡å®¢äººä¸»å‹•æå‡ºã€æè¿°çš„å•é¡Œã€ä¸é©ã€ç—‡ç‹€ã€éœ€æ±‚ã€ç…©æƒ±æˆ–æƒ³æ”¹å–„çš„éƒ¨ä½ã€‚
ï¼ˆä¾‹ï¼šç—˜ç—˜ã€æ–‘ã€é¬†å¼›ã€æ³•ä»¤ç´‹ã€è‡‰å‡¹ã€æ¯›å­”ç²—å¤§ã€æƒ³è®Šäº®ã€æƒ³æ”¹å–„è¼ªå»“ç­‰ï¼‰

è¨ºæ–·ï¼š
æŒ‡é†«å¸«æ ¹æ“šè§€å¯Ÿã€è§¸è¨ºã€å•è¨ºæ‰€æå‡ºçš„åˆ¤æ–·ã€è§€é»ã€è§£é‡‹æˆ–åˆ†æã€‚
ï¼ˆä¾‹ï¼šçš®è†šç‹€æ³ã€è‚Œè†šé¬†å¼›ç¨‹åº¦ã€éª¨æ¶ã€è„‚è‚ªåˆ†å¸ƒã€è† åŸè›‹ç™½æµå¤±ç­‰ï¼‰

å»ºè­°ï¼š
æŒ‡é†«å¸«æå‡ºçš„æ²»ç™‚é¸é …ã€æ”¹å–„æ–¹æ³•ã€æ–½æ‰“å»ºè­°ã€ç™‚ç¨‹åç¨±ã€ä¿é¤Šå»ºè­°ã€‚
ï¼ˆä¾‹ï¼šå¯ä»¥è€ƒæ…®éŸ³æ³¢ã€é›»æ³¢ã€ç»å°¿é…¸ã€çš®ç§’ã€ä¿é¤Šå»ºè­°ï¼‰

ã€åˆ†é¡è¦å‰‡ã€‘
---
åƒ…èƒ½æ ¹æ“šé€å­—ç¨¿ä¸­çš„è³‡è¨Šåˆ†é¡ï¼Œä¸å¯æ¨æ¸¬æˆ–ç¡¬è£œå…§å®¹ã€‚

å¦‚æœå…§å®¹ç„¡æ³•æ¸…æ¥šæ­¸é¡ â†’ è«‹çµ±ä¸€æ­¸åœ¨ã€Œè¨ºæ–·ã€ã€‚

è‹¥é€å­—ç¨¿æ²’æœ‰æåˆ°æŸä¸€é¡åˆ¥ï¼Œå‰‡è©²æ¬„ç•™ç©ºå³å¯ã€‚
                        
ã€è«‹ä»¥ä»¥ä¸‹æ ¼å¼è¼¸å‡ºã€‘ï¼ˆç…§æ ¼å¼å³å¯ï¼‰

ã€è¼¸å‡ºæ ¼å¼ç¯„ä¾‹ã€‘
---
ã€å®¢äººä¸»è¨´ã€‘:
- xxx
ã€è¨ºæ–·ã€‘:
- xxx
ã€å»ºè­°ã€‘:
- xxx


""")

@router.websocket("/ws/doctor")
async def websocket_endpoint(websocket: WebSocket):

    # å®‰å…¨ç™¼é€å‡½æ•¸
    async def safe_send(ws: WebSocket, data):
        """åœ¨ WebSocket é—œé–‰æ™‚å®‰å…¨ç™¼é€è¨Šæ¯"""
        try:
            await ws.send_text(data)
        except RuntimeError as e:
            print(f"âš ï¸ websocket å·²é—œé–‰ï¼Œç„¡æ³•é€è¨Šæ¯: {e}")
        except Exception as e:
            print(f"âš ï¸ ç™¼é€è¨Šæ¯æ™‚ç™¼ç”Ÿå…¶ä»–éŒ¯èª¤: {e}")

    print(f"ğŸ“¡ æ–°é€£ç·šä¾†è‡ªï¼š{websocket.client.host}:{websocket.client.port}")
    
    if len(doct_active_connections) >= DOCT_MAX_CONNECTIONS:
        await websocket.close(code=1008, reason="Connection limit exceeded")
        print(f"ğŸ”Œ é€£ç·šè¢«æ‹’çµ•ï¼šå·²é”äººæ•¸ä¸Šé™ {DOCT_MAX_CONNECTIONS}")
        return
    await websocket.accept()
    await websocket.send_text("ğŸ”Š æ–°é€£ç·šä¾†äº†")
    doct_active_connections.add(websocket) # <--- åŠ å…¥é›†åˆ
    await websocket.send_text("ğŸ”Š å·²é€£ç·šèªéŸ³è¾¨è­˜ WebSocket")
###################################################################7/3
    import uuid
    doct_session_id = str(uuid.uuid4()) #ç‚ºé€™æ¬¡å°è©±å»ºç«‹å”¯ä¸€ID
    doct_active_sessions[doct_session_id] = websocket #ç¶å®š 7/3

    doct_final_transcripts = []         #æ‰€æœ‰èªéŸ³è¾¨è­˜çµæœ(é€å­—ç¨¿)
    doct_segment_transcripts = []       #ç•¶å‰10åˆ†é˜çš„åˆ†æ®µçµæœ
    doct_all_segment_summaries = []     #æ¯æ®µçš„LLMæ‘˜è¦
    doct_all_refined_transcripts = []   #æ¯æ®µçš„æ½¤é£¾æ‘˜è¦


    doct_segment_start_time = time.time() #è¨ˆç®—æ¯æ®µé–‹å§‹æ™‚é–“
    doct_segment_duration_limit = 480  # 8 åˆ†é˜
    doct_last_audio_time = time.time() #æœ€å¾Œæ”¶åˆ°éŸ³è¨Šçš„æ™‚é–“

    doct_loop = asyncio.get_event_loop()

    # Speech config
    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=speech_region)
    speech_config.speech_recognition_language = "zh-TW"
    speech_config.endpoint_id = endpoint_id
    speech_config.set_property(speechsdk.PropertyId.Speech_SegmentationStrategy, "Semantic")

    stream = speechsdk.audio.PushAudioInputStream()
    audio_format = speechsdk.audio.AudioStreamFormat(samples_per_second=16000, bits_per_sample=16, channels=1)
    audio_config = speechsdk.audio.AudioConfig(stream=stream)
    recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)

    # å›å‚³ session_id çµ¦å‰ç«¯ 7/3
    await websocket.send_json({"type": "session_id", "session_id": doct_session_id}) 

    # åˆ†æ®µæ‘˜è¦å‡½æ•¸ä¹Ÿéœ€è¦åŠ å¼·é©—è­‰
    async def process_segment_for_summary(transcripts_to_summarize):
        if not transcripts_to_summarize or not any(t.strip() for t in transcripts_to_summarize):
            return ""
        
        segment_text = "\n".join(transcripts_to_summarize)
        if not segment_text:
            return ""
        try:
            first_summary = llm.get_summary(segment_text, summarize_prompt)    #æ½¤é£¾é€å­—ç¨¿
            summary = llm.get_summary(first_summary, doctor_system_prompt) #0724      #åˆ†é¡æ‘˜è¦
            
            # é©—è­‰æ‘˜è¦æ ¼å¼æ˜¯å¦æ­£ç¢º
            required_categories = ["å®¢äººä¸»è¨´", "è¨ºæ–·", "å»ºè­°"]  #Ë‡0807æ‹¿æ‰æ‘˜è¦
            for category in required_categories:
                if f"ã€{category}ã€‘:" not in summary:
                    print(f"âš ï¸ è­¦å‘Šï¼šæ‘˜è¦ä¸­ç¼ºå°‘ ã€{category}ã€‘: åˆ†é¡")
            
            print("ğŸ§¾ LLMå›å‚³æ½¤é£¾æ‘˜è¦åŸæ–‡ï¼š", first_summary)
            return {
                "refined_transcript": first_summary,
                "categorized_summary": summary
            }
            
        except Exception as e:
            print(f"ç²å–åˆ†æ®µLLMæ‘˜è¦æ™‚å‡ºéŒ¯: {e}")
            return f"ç²å–åˆ†æ®µæ‘˜è¦æ™‚å‡ºéŒ¯: {str(e)}"
        
    def merge_summaries_by_category(summaries: list[str]) -> dict:
        """æ”¹é€²ç‰ˆçš„åˆ†æ®µåˆä½µå‡½æ•¸"""
        categories = [
            "å®¢äººä¸»è¨´", "è¨ºæ–·", "å»ºè­°"
        ]
        merged = defaultdict(list)
        
        # print('summaries', summaries)
        
        # regexï¼šå¾ã€åˆ†é¡ã€‘é–‹å§‹ï¼Œç›´åˆ°ä¸‹ä¸€å€‹ã€åˆ†é¡ã€‘æˆ–çµå°¾
        pattern = rf"(?:ã€)?({'|'.join(categories)})(?:ã€‘)?[:ï¼š]\s*([\s\S]*?)(?=(?:ã€)?(?:{'|'.join(categories)})(?:ã€‘)?[:ï¼š]|$)"

        for summary in summaries:
            if not summary or not isinstance(summary, str):
                continue  # è·³éä¸æ˜¯å­—ä¸²çš„å…§å®¹

            matches = re.findall(pattern, summary, re.DOTALL)

            for category, content in matches:
                content = content.strip()
                lines = [line.strip() for line in content.split("\n") if line.strip()]
                for line in lines:
                    if not any(keyword in line for keyword in ["æœªæåŠ", "ç„¡ç›¸é—œ", "ç„¡", "æœª", "x"]):
                        if not line.startswith("- "):
                            line = "- " + line
                        if line not in merged[category]:
                            merged[category].append(line)


        # ç”Ÿæˆæœ€çµ‚çµæœ
        # result = []
        result_dict = {}
        for category in categories:
            if merged.get(category):    #0721
                combined = "\n".join(merged[category])    #0721
            else:    #0721
                combined = ""  # é€™è£¡æ”¹ç‚ºç©ºå­—ä¸²     #0721
            result_dict[category] = combined


        return result_dict

    
    # åˆ†æ®µæ‘˜è¦å®šæ™‚å™¨ (èƒŒæ™¯å®šæ™‚ä»»å‹™)
    async def segment_timer_task():
        nonlocal doct_segment_start_time, doct_segment_transcripts, doct_all_segment_summaries, doct_all_refined_transcripts
        try:
            print('start segment_timer_task')
            # ä¸€é–‹å§‹å°±æ½¤ç¨¿ä¸€æ¬¡ï¼ˆå¦‚æœæœ‰éŒ„éŸ³ï¼‰
            if doct_segment_transcripts:
                result = await process_segment_for_summary(doct_segment_transcripts)
                doct_all_segment_summaries.append(result["categorized_summary"])
                doct_all_refined_transcripts.append(result["refined_transcript"])
                doct_segment_transcripts.clear()
            # é€²å…¥å®šæ™‚æª¢æŸ¥è¿´åœˆ (éŒ„éŸ³æ™‚é–“è¶…éé™åˆ¶)
            while True:
                await asyncio.sleep(10)
                now = time.time()
                if now - doct_segment_start_time >= doct_segment_duration_limit:
                    if doct_segment_transcripts:
                        #result = await loop.run_in_executor(None, lambda: llm.get_summary("\n".join(segment_transcripts), summarize_prompt))
                        result = await process_segment_for_summary(doct_segment_transcripts)
                        doct_all_segment_summaries.append(result["categorized_summary"])
                        doct_all_refined_transcripts.append(result["refined_transcript"])
                        await safe_send(websocket, json.dumps({
                            "type": "segment_summary",
                            "summary": result["categorized_summary"]
                        }))
                        doct_segment_transcripts.clear()
                    doct_segment_start_time = now

        except asyncio.CancelledError:
            print("â¹ åˆ†æ®µä»»å‹™å·²å–æ¶ˆ")

    #######################################åŠ å…¥éœéŸ³åµæ¸¬

    async def check_silence():
        """èƒŒæ™¯ä»»å‹™ï¼šæª¢æŸ¥æ˜¯å¦è¶…é10ç§’æ²’æ”¶åˆ°éŸ³è¨Š"""
        nonlocal doct_last_audio_time, doct_segment_transcripts, doct_all_segment_summaries, doct_all_refined_transcripts, doct_segment_start_time

        try:
            print('start check silence')
            while True:
                await asyncio.sleep(1)  # æ¯ç§’æª¢æŸ¥ä¸€æ¬¡
                if time.time() - doct_last_audio_time > 10:  # è¶…é 10 ç§’æ²’æ”¶åˆ°éŸ³è¨Š
                    print("âš ï¸ è¶…é 10 ç§’æœªæ”¶åˆ°éŸ³è¨Š")
                    await websocket.send_json({
                        "type": "error",
                        "message": "æœªæª¢æ¸¬åˆ°èªéŸ³ï¼Œè«‹ç¢ºèªéº¥å…‹é¢¨æ˜¯å¦æœ‰è²éŸ³"
                    })
                    if doct_segment_transcripts and websocket.client_state == websockets.CONNECTED:  # âœ… flush ç•¶å‰ç´¯ç©çš„æ–‡å­—
                        try: 
                            result = await process_segment_for_summary(doct_segment_transcripts)
                            doct_all_segment_summaries.append(result["categorized_summary"])
                            doct_all_refined_transcripts.append(result["refined_transcript"])
                            await safe_send(websocket, json.dumps({
                                "type": "segment_summary",
                                "summary": result["categorized_summary"]
                            }))
                            doct_segment_transcripts.clear()
                            #flushå¾Œé‡ç½®æ™‚é–“
                            # segment_start_time = time.time()
                        except Exception as e:
                            print(f"âš ï¸ éœéŸ³ flush å‡ºéŒ¯: {e}")
                    
                    # ç™¼é€æç¤ºè¨Šæ¯çµ¦å‰ç«¯
                    try: 
                        await websocket.send_json({
                        "type": "error",
                        "message": "æœªæª¢æ¸¬åˆ°èªéŸ³ï¼Œè«‹ç¢ºèªéº¥å…‹é¢¨æ˜¯å¦æœ‰è²éŸ³"
                    })
                    except Exception as e:
                        print(f"âš ï¸ ç™¼é€éœéŸ³æç¤ºå¤±æ•—: {e}")

        except asyncio.CancelledError:
            print("â¹ éœéŸ³æª¢æŸ¥ä»»å‹™å·²å–æ¶ˆ")

        # æ¥æ”¶è¾¨è­˜çµæœ
    def recognized_callback(evt):
        if evt.result.reason == speechsdk.ResultReason.RecognizedSpeech:
            text = evt.result.text
            doct_final_transcripts.append(text)
            doct_segment_transcripts.append(text)
            # asyncio.run_coroutine_threadsafe(websocket.send_text(text), loop)
            asyncio.run_coroutine_threadsafe(
                safe_send(websocket, text),
                doct_loop
            )

    recognizer.recognized.connect(recognized_callback)
    recognizer.start_continuous_recognition()

    await websocket.send_text(json.dumps({
        "type": "session_id",
        "session_id": doct_session_id
    }))


    timer_task = asyncio.create_task(segment_timer_task())
    silence_task = asyncio.create_task(check_silence())

    try:
        while True:
            msg = await websocket.receive()   #0723
            # print("ğŸ“© raw message:", msg, flush=True)
            # try:
            #     msg = await asyncio.wait_for(websocket.receive(), timeout=1)
            # except asyncio.TimeoutError:
            #     # æ¯ 1 ç§’æª¢æŸ¥ä¸€æ¬¡é€£ç·šç‹€æ…‹
            #     continue
            if isinstance(msg, dict):
                # if msg.get("type") == "websocket.disconnect":
                #     print('sssssssssssssss websocket disconnect')
                #     break           

                # è™•ç†æ–‡å­—è¨Šæ¯ (åŒ…æ‹¬ "stop" æŒ‡ä»¤)
                if msg.get("type") == "websocket.receive":
                    if "text" in msg:
                        text_data = msg["text"].strip()
                        print(f"ğŸ“ Received text message: {text_data}")

                        # æª¢æŸ¥æ˜¯å¦ç‚º "stop" æŒ‡ä»¤
                        if text_data == "stop":
                            print("ğŸ›‘ Received 'stop' command")
                            print(f"ğŸ•’ Stop command received at: {time.time()}")
                            break

                        # å¦‚æœæ˜¯ JSON æŒ‡ä»¤ï¼Œå¯ä»¥é€™æ¨£è§£æï¼š
                        try:
                            json_data = json.loads(text_data)
                            if json_data.get("command") == "stop":
                                print("ğŸ›‘ Received JSON stop command")
                                break
                        except json.JSONDecodeError:
                            pass  # é JSON è¨Šæ¯ï¼Œå¿½ç•¥

                    # è™•ç†äºŒé€²ä½æ•¸æ“š (éŸ³è¨Š)
                    elif "bytes" in msg:
                        if msg["bytes"]:
                            stream.write(msg["bytes"])
                            last_audio_time = time.time()
                    else: 
                        print("âš ï¸ æ”¶åˆ°ç©ºéŸ³è¨Šï¼Œæœªæª¢æ¸¬åˆ°è²éŸ³")
                        # é€™é‚Šä½ å¯ä»¥é¸æ“‡å‚³å›å‰ç«¯éŒ¯èª¤è¨Šæ¯
                        await websocket.send_json({
                            "type": "error",
                            "message": "æœªæª¢æ¸¬åˆ°èªéŸ³ï¼Œè«‹ç¢ºèªéº¥å…‹é¢¨æ˜¯å¦æœ‰è²éŸ³"
                        })

            else:
                print(f"âš ï¸ æ”¶åˆ°é dict çš„è¨Šæ¯: {msg}")


        recognizer.stop_continuous_recognition()
        stream.close()
        timer_task.cancel()
        silence_task.cancel()

        if doct_final_transcripts: #æœ‰è½‰å‡ºæ–‡å­—æ‰åšå¾ŒçºŒ
            # âœ¨ æœ€å¾Œä¸€æ®µè£œæ‘˜è¦
            if doct_segment_transcripts:
                result = await process_segment_for_summary(doct_segment_transcripts)
                doct_all_segment_summaries.append(result["categorized_summary"])  #åªå­˜åˆ†é¡æ‘˜è¦
                doct_all_refined_transcripts.append(result["refined_transcript"])
                doct_segment_transcripts.clear()

            # çµ„åˆæœ€çµ‚æ‘˜è¦èˆ‡é€å­—ç¨¿
            #final_combined_summary = "\n\n".join(all_segment_summaries)
            doct_final_refined_transcript = "\n".join(doct_all_refined_transcripts).strip()
            doct_final_combined_summary = merge_summaries_by_category(doct_all_segment_summaries)
            doct_summary_results[doct_session_id] = doct_final_combined_summary
            doct_final_text = "\n".join(doct_final_transcripts)
            doct_final_results[doct_session_id] = doct_final_text

            # print("ğŸ“ æœ€çµ‚åˆä½µæ‘˜è¦ï¼š", final_combined_summary)
            print("ğŸ“ æœ€çµ‚é†«ç”Ÿå®Œæ•´é€å­—ç¨¿ï¼š", doct_final_text)
            print("ğŸ“ æœ€çµ‚é†«ç”Ÿå®Œæ•´æ½¤é£¾ç¨¿ï¼š", doct_final_refined_transcript)
            print("ğŸ“ ä¸­æ–·äº†è·‘å‡ºsession_idï¼š", doct_session_id) #7/3
            
            # åœ¨é€™è£¡å‚³é€æœ€çµ‚æ‘˜è¦å®Œæˆé€šçŸ¥ 7/23
            await websocket.send_text(json.dumps({
                "type": "final_summary_ready",
                "session_id": doct_session_id
            }))
            #å‚³é€åˆä½µæ½¤é£¾æ
            await websocket.send_text(json.dumps({
                "type": "final_refined_transcript",
                "session_id": doct_session_id,
                "refined_transcript": doct_final_refined_transcript
            }))
            # æœ€çµ‚å®Œæ•´é€å­—ç¨¿
            await websocket.send_text(json.dumps({
                "type": "final_combined_text",
                "session_id": doct_session_id,
                "summary": doct_final_text
            }))
            # æœ€çµ‚æ‘˜è¦è³‡æ–™ä¹Ÿé€éå»
            await websocket.send_text(json.dumps({
                "type": "final_combined_summary",
                "session_id": doct_session_id,
                "summary": doct_final_combined_summary
            }))
            return doct_final_refined_transcript
        # æ¥ä¸‹ä¾†æ˜¯è™•ç†ç•°å¸¸ï¼Œç¢ºä¿æ•æ‰åˆ°å‰ç«¯ä¸­æ–·
    except WebSocketDisconnect:
        # æ•æ‰å‰ç«¯ close() å¼•ç™¼çš„ä¸­æ–·
        print(f"ğŸ”Œ WebSocketDisconnect (Frontend Close) detected.")
        # ğŸš¨ ä¿®æ­£ï¼šå°å‡ºä¸­æ–·æ™‚çš„æ™‚é–“
        print(f"ğŸ•’ WebSocket disconnected at: {time.time()}")
        pass # è®“æµç¨‹ç¹¼çºŒåˆ°ä¸‹æ–¹çš„ LLM è™•ç†å€å¡Š


    except Exception as e:
        print(f"è™•ç†èªéŸ³è³‡æ–™æ™‚å‡ºéŒ¯: {e}")
        recognizer.stop_continuous_recognition()
        stream.close()
        timer_task.cancel()
        try:
            await timer_task
        except asyncio.CancelledError:
            pass
    
    finally: # <--- ä½¿ç”¨ finally ç¢ºä¿ç„¡è«–å¦‚ä½•éƒ½æœƒåŸ·è¡Œ
        # ç¢ºä¿è³‡æºè¢«æ¸…ç†
        if 'timer_task' in locals() and not timer_task.done():
            timer_task.cancel()
            try:
                await timer_task
            except asyncio.CancelledError:
                pass
        
        if websocket in doct_active_connections:
            doct_active_connections.remove(websocket)
        
        doct_active_sessions.pop(doct_session_id, None)
        print(f"ğŸ”Œ é†«ç”Ÿé€£ç·šå·²é—œé–‰ (Session: {doct_session_id})ï¼Œç›®å‰é€£ç·šæ•¸: {len(doct_active_connections)}")



